# === OpenAI / API Configuration ===
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini

# For Nemotron or other OpenAI-compatible endpoints:
# OPENAI_BASE_URL=https://integrate.api.nvidia.com/v1
# OPENAI_MODEL=nemotron-4-340b-instruct  # Example model name

# If using a project-scoped key (sk-proj-...), include:
# OPENAI_PROJECT_ID=proj_1234567890abcdef

# === AI Bash Runtime Configuration ===
AI_BASH_SANDBOX=/path/to/safe/dir
AI_BASH_MAX_STDIO_BYTES=131072   # Max bytes captured from stdout/stderr
AI_BASH_MAX_TOKENS=256           # Token limit per API call
AI_BASH_FAST_MODE=1              # Skip planner/critic (faster)
AI_BASH_DEBUG=0                  # 1 = verbose debug logs
AI_BASH_AUTO_CONFIRM=0           # 1 = auto-run risky commands (use with caution)
AI_BASH_NL2CMD=1                 # Enable natural-languageâ†’command generation

# === Notes ===
# - Commands are executed only inside AI_BASH_SANDBOX.
# - Use 'export' only in interactive shells; .env files do not require it.
# - To enable debug mode temporarily:
#   export AI_BASH_DEBUG=1
# - To disable:
#   unset AI_BASH_DEBUG

